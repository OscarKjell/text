---
title: "The Language-Based Assessment Model (L-BAM) Library"
vignette: >
  %\VignetteIndexEntry{LBAM}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


The L-BAM library comprises information about pre-trained models. The models can be called with `textPredict()`, `textAssess()` or `textClassify()` like this:

```{r textPredict_examples, eval = FALSE, echo=TRUE}
library(text)

# Example calling a model using the URL
textPredict(
  model_info = "facebook_valence",
  texts = "what is the valence of this text?"
)


# Example calling a model having an abbreviation
textClassify(
  model_info = "implicit_power_fine_tuned_roberta",
  texts = "It looks like they have problems collaborating."
)
```

The text prediction functions can be given a model and a text, and automatically transform the text to word embeddings and produce estimated scores or probabilities.

If you want to add a pre-trained model to the L-BAM library, please fill out the details in this [Google sheet](https://docs.google.com/spreadsheets/d/1K16JdK7zOmuRktqgaYs5sgaHnkUVwB9v6ERxZdd9iW8/edit#gid=0) and email us (*oscar [ d_o t] kjell [a _ t] psy [DOT] lu [d_o_t]se*) so that we can update the table online.

*Note that you can adjust the width of the columns when scrolling the table.*

```{r models_table, eval = TRUE, echo=FALSE}
library("reactable")
# see vignette: https://glin.github.io/reactable/articles/examples.html#custom-rendering

model_data <- read.csv(system.file("extdata",
                                   "The_L-BAM_Library.csv",
                                   package = "text"),
                       header = TRUE, 
                       skip = 3)

reactable::reactable(
  data = model_data,
  filterable = TRUE,
  defaultPageSize = 10,
  highlight = TRUE, 
  resizable = TRUE,
  theme = reactableTheme(
    borderColor = "#1f7a1f",
  #  stripedColor = "#e6ffe6",
    highlightColor = "#ebfaeb",
    cellPadding = "8px 12px",
    style = list(fontFamily = "-apple-system, BlinkMacSystemFont, Segoe UI, Helvetica, Arial, sans-serif")
  ),
  columns = list(
    Construct_Concept_Behaviours = colDef(minWidth = 280),
    Outcome = colDef(minWidth = 280),
    Language = colDef(minWidth = 280),
    Language_type = colDef(minWidth = 280),
    Level = colDef(minWidth = 280),
    N_training = colDef(minWidth = 280),
    Source = colDef(minWidth = 280),
    Participants = colDef(minWidth = 280),
    Label_types = colDef(minWidth = 280),
    Language_domain_distribution = colDef(minWidth = 280),
    Open_data = colDef(minWidth = 280),
    Model_type = colDef(minWidth = 280),
    Features = colDef(minWidth = 280),
    Validation_metric1 = colDef(minWidth = 280),
    N_fold_cv_accuracy.1 = colDef(minWidth = 280),
    Held_out_accuracy.1 = colDef(minWidth = 280),
    SEMP_accuracy.1 = colDef(minWidth = 280),
    Other_metrics_n_fold_cv = colDef(minWidth = 280),
    Other_metrics_held_out = colDef(minWidth = 280),
    Other_metrics_SEMP = colDef(minWidth = 280),
    Ethical_approval = colDef(minWidth = 280),
    Ethical_statement = colDef(minWidth = 280),
    Reference = colDef(minWidth = 280),
    Date = colDef(minWidth = 280),
    Contact_details = colDef(minWidth = 280),
    License = colDef(minWidth = 280),
    Study_type = colDef(minWidth = 280),
    Original = colDef(minWidth = 280),
    Miscellaneous = colDef(minWidth = 280),
    Command_info = colDef(minWidth = 800),
    Name = colDef(minWidth = 280),
    Path = colDef(minWidth = 280),
    Model_Type = colDef(minWidth = 280)
  ), 
  showPageSizeOptions = TRUE,
  groupBy = "Construct_Concept_Behaviours"
)
```


### References

Gu, Kjell, Schwartz & Kjell. (2024). Natural Language Response Formats for Assessing Depression and Worry with Large Language Models: A Sequential Evaluation with Model Pre-registration.

Kjell, O. N., Sikström, S., Kjell, K., & Schwartz, H. A. (2022). Natural language analyzed with AI-based transformers predict traditional subjective well-being measures approaching the theoretical upper limits in accuracy. Scientific reports, 12(1), 3918.

Nilsson, Runge, Ganesan, Lövenstierne, Soni & Kjell (2024) Automatic Implicit Motives Codings are at Least as Accurate as Humans’ and 99% Faster
