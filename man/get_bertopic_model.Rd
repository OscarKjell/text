% Generated by roxygen2: do not edit by hand
<<<<<<<< HEAD:man/textTopics.Rd
% Please edit documentation in R/7_1_textTopic.R
\name{textTopics}
\alias{textTopics}
\title{BERTopic implementation with prediction extraction (EXPERIMENTAL - saving training-data)}
\usage{
textTopics(
========
% Please edit documentation in R/7_1_bert_topic.R
\name{get_bertopic_model}
\alias{get_bertopic_model}
\title{BERTopic implementation with prediction extraction}
\usage{
get_bertopic_model(
>>>>>>>> parent of 51d990a (updating parameter and function name, updating the test, harmonising python packages and cleaning R-code.):man/get_bertopic_model.Rd
  data,
  data_var,
  embedding_model = "default",
  umap_model = "default",
  hdbscan_model = "default",
  vectorizer_model = "default",
  representation_model = "default",
  num_top_words = 10,
  n_gram_range = c(1, 3),
<<<<<<<< HEAD:man/textTopics.Rd
  stopwords = "english",
  min_df = 10,
  bm25_weighting = FALSE,
  reduce_frequent_words = TRUE,
  seed = 2024,
========
  stop_words = "english",
  min_df = min_df,
  bm25_weighting = bm25_weighting,
  reduce_frequent_words = reduce_frequent_words,
  seed = 1234,
>>>>>>>> parent of 51d990a (updating parameter and function name, updating the test, harmonising python packages and cleaning R-code.):man/get_bertopic_model.Rd
  save_dir = "./results"
)
}
\arguments{
\item{data}{(data.frame)}

\item{data_var}{(string)  data variable to perform topic modeling on}

\item{embedding_model}{(string) embedding model to use for embedding data, choose from miniLM, mpnet, multi-mpnet, distilroberta}

\item{umap_model}{(string) dimension reduction algorithm, currently only "default" supported}

\item{hdbscan_model}{(string) clustering algorihtm, currently only "default" supported}

\item{vectorizer_model}{(string) vectorizer model, currently only "default" supported}

\item{representation_model}{(string) representation models used for topics, "keybert" or "mmr"}

\item{num_top_words}{(int) determine the number of top words for each topic}

\item{n_gram_range}{(list) ngram range used for vectorizer model}

\item{stopwords}{(string)}

\item{min_df}{(int) minimum document frequency of terms}

\item{bm25_weighting}{(bool) determine whether bm25_weighting is used for ClassTfidfTransformer}

\item{reduce_frequent_words}{(bool) determine whether frequent words are reduced by ClassTfidfTransformer}

\item{seed}{(int) set random seed for intialization of umap model}

\item{save_dir}{(string) set directory for saving results, defaults to "./results"}
}
\value{
A folder containing the model, data, another folder with terms and values for each topic, document-topic matrix
}
\description{
<<<<<<<< HEAD:man/textTopics.Rd
BERTopic implementation with prediction extraction (EXPERIMENTAL - saving training-data)
========
BERTopic implementation with prediction extraction
>>>>>>>> parent of 51d990a (updating parameter and function name, updating the test, harmonising python packages and cleaning R-code.):man/get_bertopic_model.Rd
}
